{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IREE Cross Compilation Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FH3IRpYTta2v"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH3IRpYTta2v"
      },
      "source": [
        "##### Copyright 2022 The IREE Authors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWGa71_Ct2ug",
        "cellView": "form"
      },
      "source": [
        "#@title Licensed under the Apache License v2.0 with LLVM Exceptions.\n",
        "# See https://llvm.org/LICENSE.txt for license information.\n",
        "# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5s6ncerSpc5"
      },
      "source": [
        "# IREE Cross Compilation Demo July 13, 2022"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2bScbYkP6VZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "051e7154-b180-4b98-ae06-002f8129992a",
        "cellView": "form"
      },
      "source": [
        "#@title Setup\n",
        "\n",
        "!python -m pip install iree-compiler iree-runtime iree-tools-tf -f https://github.com/iree-org/iree/releases/tag/candidate-20220713.203\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "import tensorflow as tf\n",
        "\n",
        "ARTIFACTS_DIR = os.path.join(tempfile.gettempdir(), \"iree\", \"colab_artifacts\")\n",
        "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
        "# %env IREE_SAVE_TEMPS=$ARTIFACTS_DIR/temps\n",
        "print(f\"Using artifacts directory '{ARTIFACTS_DIR}'\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://github.com/iree-org/iree/releases/tag/candidate-20220713.203\n",
            "Collecting iree-compiler\n",
            "  Downloading https://github.com/iree-org/iree/releases/download/candidate-20220713.203/iree_compiler-20220713.203-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 12.2 MB/s \n",
            "\u001b[?25hCollecting iree-runtime\n",
            "  Downloading https://github.com/iree-org/iree/releases/download/candidate-20220713.203/iree_runtime-20220713.203-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 25.2 MB/s \n",
            "\u001b[?25hCollecting iree-tools-tf\n",
            "  Downloading https://github.com/iree-org/iree/releases/download/candidate-20220713.203/iree_tools_tf-20220713.203-py3-none-linux_x86_64.whl (58.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 58.5 MB 25 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from iree-compiler) (1.21.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from iree-compiler) (3.13)\n",
            "Installing collected packages: iree-tools-tf, iree-runtime, iree-compiler\n",
            "Successfully installed iree-compiler-20220713.203 iree-runtime-20220713.203 iree-tools-tf-20220713.203\n",
            "Using artifacts directory '/tmp/iree/colab_artifacts'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwApbPstraWZ"
      },
      "source": [
        "class DemoModule(tf.Module):\n",
        "  # reduce_sum (dynamic input size, static output size)\n",
        "  #   e.g. [1.0, 2.0, 3.0] -> 6.0\n",
        "  @tf.function(input_signature=[tf.TensorSpec([None], tf.float32)])\n",
        "  def reduce_sum(self, values):\n",
        "    return tf.math.reduce_sum(values)\n",
        "\n",
        "  # reduce_mean (dynamic input size, static output size)\n",
        "  #   e.g. [1.0, 2.0, 3.0] -> 2.0\n",
        "  @tf.function(input_signature=[tf.TensorSpec([None], tf.float32)])\n",
        "  def reduce_mean(self, values):\n",
        "    return tf.math.reduce_mean(values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nSXZiZ_X8-P",
        "outputId": "776ab3c7-b51b-4901-b800-b9ce1862860d",
        "cellView": "form"
      },
      "source": [
        "#@title Import into MLIR\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from iree.compiler import tf as tfc\n",
        "\n",
        "compiler_module = tfc.compile_module(\n",
        "    DemoModule(), import_only=True, output_mlir_debuginfo=False, output_generic_mlir=False)\n",
        "clear_output()  # Skip over TensorFlow's output.\n",
        "print(\"Demo MLIR (imported):\\n```\\n%s```\\n\" % compiler_module.decode(\"utf-8\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demo MLIR (imported):\n",
            "```\n",
            "\"builtin.module\"() ({\n",
            "  \"func.func\"() ({\n",
            "  ^bb0(%arg0: !iree_input.buffer_view):\n",
            "    %0 = \"iree_input.cast.buffer_view_to_tensor\"(%arg0) : (!iree_input.buffer_view) -> tensor<?xf32>\n",
            "    %1 = \"func.call\"(%0) {callee = @__inference_reduce_mean_70} : (tensor<?xf32>) -> tensor<f32>\n",
            "    %2 = \"iree_input.cast.tensor_to_buffer_view\"(%1) : (tensor<f32>) -> !iree_input.buffer_view\n",
            "    \"func.return\"(%2) : (!iree_input.buffer_view) -> ()\n",
            "  }) {function_type = (!iree_input.buffer_view) -> !iree_input.buffer_view, iree.abi = \"{\\22a\\22:[[\\22ndarray\\22,\\22f32\\22,1,null]],\\22r\\22:[[\\22ndarray\\22,\\22f32\\22,0]],\\22v\\22:1}\", sym_name = \"reduce_mean\"} : () -> ()\n",
            "  \"func.func\"() ({\n",
            "  ^bb0(%arg0: tensor<?xf32>):\n",
            "    %0 = \"arith.constant\"() {value = 0 : index} : () -> index\n",
            "    %1 = \"mhlo.constant\"() {value = dense<-0.000000e+00> : tensor<f32>} : () -> tensor<f32>\n",
            "    %2 = \"mhlo.reduce\"(%arg0, %1) ({\n",
            "    ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n",
            "      %8 = \"mhlo.add\"(%arg1, %arg2) : (tensor<f32>, tensor<f32>) -> tensor<f32>\n",
            "      \"mhlo.return\"(%8) : (tensor<f32>) -> ()\n",
            "    }) {dimensions = dense<0> : tensor<1xi64>} : (tensor<?xf32>, tensor<f32>) -> tensor<f32>\n",
            "    %3 = \"tensor.dim\"(%arg0, %0) : (tensor<?xf32>, index) -> index\n",
            "    %4 = \"arith.index_cast\"(%3) : (index) -> i64\n",
            "    %5 = \"tensor.from_elements\"(%4) : (i64) -> tensor<i64>\n",
            "    %6 = \"mhlo.convert\"(%5) : (tensor<i64>) -> tensor<f32>\n",
            "    %7 = \"chlo.broadcast_divide\"(%2, %6) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<f32>) -> tensor<f32>\n",
            "    \"func.return\"(%7) : (tensor<f32>) -> ()\n",
            "  }) {arg_attrs = [{tf._user_specified_name = \"values\"}], function_type = (tensor<?xf32>) -> tensor<f32>, sym_name = \"__inference_reduce_mean_70\", sym_visibility = \"private\", tf._construction_context = \"kEagerRuntime\", tf._input_shapes = [#tf_type.shape<?>]} : () -> ()\n",
            "  \"func.func\"() ({\n",
            "  ^bb0(%arg0: !iree_input.buffer_view):\n",
            "    %0 = \"mhlo.constant\"() {value = dense<-0.000000e+00> : tensor<f32>} : () -> tensor<f32>\n",
            "    %1 = \"iree_input.cast.buffer_view_to_tensor\"(%arg0) : (!iree_input.buffer_view) -> tensor<?xf32>\n",
            "    %2 = \"mhlo.reduce\"(%1, %0) ({\n",
            "    ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n",
            "      %4 = \"mhlo.add\"(%arg1, %arg2) : (tensor<f32>, tensor<f32>) -> tensor<f32>\n",
            "      \"mhlo.return\"(%4) : (tensor<f32>) -> ()\n",
            "    }) {dimensions = dense<0> : tensor<1xi64>} : (tensor<?xf32>, tensor<f32>) -> tensor<f32>\n",
            "    %3 = \"iree_input.cast.tensor_to_buffer_view\"(%2) : (tensor<f32>) -> !iree_input.buffer_view\n",
            "    \"func.return\"(%3) : (!iree_input.buffer_view) -> ()\n",
            "  }) {function_type = (!iree_input.buffer_view) -> !iree_input.buffer_view, iree.abi = \"{\\22a\\22:[[\\22ndarray\\22,\\22f32\\22,1,null]],\\22r\\22:[[\\22ndarray\\22,\\22f32\\22,0]],\\22v\\22:1}\", sym_name = \"reduce_sum\"} : () -> ()\n",
            "}) : () -> ()\n",
            "\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF0dzDsbaP2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031d780f-4e44-4c9f-87ab-6b3f50a3a323",
        "cellView": "form"
      },
      "source": [
        "#@title Compile to IREE .vmfb files\n",
        "\n",
        "from iree.compiler import compile_str\n",
        "\n",
        "vmvx_blob = compile_str(\n",
        "    compiler_module,\n",
        "    input_type=\"mhlo\",\n",
        "    target_backends=[\"vmvx\"],\n",
        "    extra_args=[\"--mlir-print-ir-after=iree-mhlo-to-linalg-on-tensors\"])\n",
        "vmvx_path = os.path.join(ARTIFACTS_DIR, \"demo_vmvx.vmfb\")\n",
        "with open(vmvx_path, \"wb\") as output_file:\n",
        "  output_file.write(vmvx_blob)\n",
        "print(f\"Wrote .vmfb to path '{vmvx_path}'\")\n",
        "\n",
        "wasm_blob = compile_str(\n",
        "    compiler_module,\n",
        "    input_type=\"mhlo\",\n",
        "    target_backends=[\"llvm\"],\n",
        "    extra_args=[\"--iree-llvm-target-triple=wasm32-unknown-emscripten\"])\n",
        "wasm_path = os.path.join(ARTIFACTS_DIR, \"demo_wasm.vmfb\")\n",
        "with open(wasm_path, \"wb\") as output_file:\n",
        "  output_file.write(wasm_blob)\n",
        "print(f\"Wrote .vmfb to path '{wasm_path}'\")\n",
        "\n",
        "android_cpu_blob = compile_str(\n",
        "    compiler_module,\n",
        "    input_type=\"mhlo\",\n",
        "    target_backends=[\"llvm\"],\n",
        "    extra_args=[\"--iree-llvm-target-triple=aarch64-none-linux-android29\"])\n",
        "android_cpu_path = os.path.join(ARTIFACTS_DIR, \"demo_android-cpu-arm64-v8a.vmfb\")\n",
        "with open(android_cpu_path, \"wb\") as output_file:\n",
        "  output_file.write(android_cpu_blob)\n",
        "print(f\"Wrote .vmfb to path '{android_cpu_path}'\")\n",
        "\n",
        "android_gpu_blob = compile_str(\n",
        "    compiler_module,\n",
        "    input_type=\"mhlo\",\n",
        "    target_backends=[\"vulkan-spirv\"],\n",
        "    extra_args=[\"--iree-vulkan-target-triple=valhall-unknown-android11\"])\n",
        "android_gpu_path = os.path.join(ARTIFACTS_DIR, \"demo_android-gpu-mali.vmfb\")\n",
        "with open(android_gpu_path, \"wb\") as output_file:\n",
        "  output_file.write(android_gpu_blob)\n",
        "print(f\"Wrote .vmfb to path '{android_gpu_path}'\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "// -----// IR Dump After ConvertMHLOToLinalgOnTensors //----- //\n",
            "func.func @reduce_mean(%arg0: !iree_input.buffer_view loc(\"<stdin>\":3:8)) -> !iree_input.buffer_view attributes {iree.abi = \"{\\22a\\22:[[\\22ndarray\\22,\\22f32\\22,1,null]],\\22r\\22:[[\\22ndarray\\22,\\22f32\\22,0]],\\22v\\22:1}\"} {\n",
            "  %0 = iree_input.cast.buffer_view_to_tensor %arg0 : !iree_input.buffer_view -> tensor<?xf32> loc(\"<stdin>\":4:10)\n",
            "  %1 = call @__inference_reduce_mean_70(%0) : (tensor<?xf32>) -> tensor<f32> loc(\"<stdin>\":5:10)\n",
            "  %2 = iree_input.cast.tensor_to_buffer_view %1 : tensor<f32> -> !iree_input.buffer_view loc(\"<stdin>\":6:10)\n",
            "  return %2 : !iree_input.buffer_view loc(\"<stdin>\":7:5)\n",
            "} loc(\"<stdin>\":2:3)\n",
            "\n",
            "// -----// IR Dump After ConvertMHLOToLinalgOnTensors //----- //\n",
            "func.func private @__inference_reduce_mean_70(%arg0: tensor<?xf32> {tf._user_specified_name = \"values\"} loc(\"<stdin>\":10:8)) -> tensor<f32> attributes {tf._construction_context = \"kEagerRuntime\", tf._input_shapes = [#tf_type.shape<?>]} {\n",
            "  %c0 = arith.constant 0 : index loc(\"<stdin>\":11:10)\n",
            "  %cst = arith.constant dense<-0.000000e+00> : tensor<f32> loc(\"<stdin>\":12:10)\n",
            "  %cst_0 = arith.constant -0.000000e+00 : f32 loc(\"<stdin>\":13:10)\n",
            "  %0 = linalg.init_tensor [] : tensor<f32> loc(\"<stdin>\":13:10)\n",
            "  %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<f32>) -> tensor<f32> loc(\"<stdin>\":13:10)\n",
            "  %2 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> ()>], iterator_types = [\"reduction\"]} ins(%arg0 : tensor<?xf32>) outs(%1 : tensor<f32>) {\n",
            "  ^bb0(%arg1: f32 loc(unknown), %arg2: f32 loc(unknown)):\n",
            "    %10 = arith.addf %arg1, %arg2 : f32 loc(\"<stdin>\":15:12)\n",
            "    linalg.yield %10 : f32 loc(\"<stdin>\":16:7)\n",
            "  } -> tensor<f32> loc(\"<stdin>\":13:10)\n",
            "  %3 = tensor.dim %arg0, %c0 : tensor<?xf32> loc(\"<stdin>\":18:10)\n",
            "  %4 = arith.index_cast %3 : index to i32 loc(\"<stdin>\":19:10)\n",
            "  %5 = tensor.from_elements %4 : tensor<i32> loc(\"<stdin>\":20:10)\n",
            "  %6 = linalg.init_tensor [] : tensor<f32> loc(\"<stdin>\":21:10)\n",
            "  %7 = linalg.generic {indexing_maps = [affine_map<() -> ()>, affine_map<() -> ()>], iterator_types = []} ins(%5 : tensor<i32>) outs(%6 : tensor<f32>) {\n",
            "  ^bb0(%arg1: i32 loc(\"<stdin>\":20:10), %arg2: f32 loc(\"<stdin>\":21:10)):\n",
            "    %10 = arith.sitofp %arg1 : i32 to f32 loc(\"<stdin>\":21:10)\n",
            "    linalg.yield %10 : f32 loc(\"<stdin>\":21:10)\n",
            "  } -> tensor<f32> loc(\"<stdin>\":21:10)\n",
            "  %8 = linalg.init_tensor [] : tensor<f32> loc(\"<stdin>\":22:10)\n",
            "  %9 = linalg.generic {indexing_maps = [affine_map<() -> ()>, affine_map<() -> ()>, affine_map<() -> ()>], iterator_types = []} ins(%2, %7 : tensor<f32>, tensor<f32>) outs(%8 : tensor<f32>) {\n",
            "  ^bb0(%arg1: f32 loc(\"<stdin>\":13:10), %arg2: f32 loc(\"<stdin>\":21:10), %arg3: f32 loc(\"<stdin>\":22:10)):\n",
            "    %10 = arith.divf %arg1, %arg2 : f32 loc(\"<stdin>\":22:10)\n",
            "    linalg.yield %10 : f32 loc(\"<stdin>\":22:10)\n",
            "  } -> tensor<f32> loc(\"<stdin>\":22:10)\n",
            "  return %9 : tensor<f32> loc(\"<stdin>\":23:5)\n",
            "} loc(\"<stdin>\":9:3)\n",
            "\n",
            "// -----// IR Dump After ConvertMHLOToLinalgOnTensors //----- //\n",
            "func.func @reduce_sum(%arg0: !iree_input.buffer_view loc(\"<stdin>\":26:8)) -> !iree_input.buffer_view attributes {iree.abi = \"{\\22a\\22:[[\\22ndarray\\22,\\22f32\\22,1,null]],\\22r\\22:[[\\22ndarray\\22,\\22f32\\22,0]],\\22v\\22:1}\"} {\n",
            "  %cst = arith.constant dense<-0.000000e+00> : tensor<f32> loc(\"<stdin>\":27:10)\n",
            "  %0 = iree_input.cast.buffer_view_to_tensor %arg0 : !iree_input.buffer_view -> tensor<?xf32> loc(\"<stdin>\":28:10)\n",
            "  %cst_0 = arith.constant -0.000000e+00 : f32 loc(\"<stdin>\":29:10)\n",
            "  %1 = linalg.init_tensor [] : tensor<f32> loc(\"<stdin>\":29:10)\n",
            "  %2 = linalg.fill ins(%cst_0 : f32) outs(%1 : tensor<f32>) -> tensor<f32> loc(\"<stdin>\":29:10)\n",
            "  %3 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> ()>], iterator_types = [\"reduction\"]} ins(%0 : tensor<?xf32>) outs(%2 : tensor<f32>) {\n",
            "  ^bb0(%arg1: f32 loc(unknown), %arg2: f32 loc(unknown)):\n",
            "    %5 = arith.addf %arg1, %arg2 : f32 loc(\"<stdin>\":31:12)\n",
            "    linalg.yield %5 : f32 loc(\"<stdin>\":32:7)\n",
            "  } -> tensor<f32> loc(\"<stdin>\":29:10)\n",
            "  %4 = iree_input.cast.tensor_to_buffer_view %3 : tensor<f32> -> !iree_input.buffer_view loc(\"<stdin>\":34:10)\n",
            "  return %4 : !iree_input.buffer_view loc(\"<stdin>\":35:5)\n",
            "} loc(\"<stdin>\":25:3)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote .vmfb to path '/tmp/iree/colab_artifacts/demo_vmvx.vmfb'\n",
            "Wrote .vmfb to path '/tmp/iree/colab_artifacts/demo_wasm.vmfb'\n",
            "Wrote .vmfb to path '/tmp/iree/colab_artifacts/demo_android-cpu-arm64-v8a.vmfb'\n",
            "Wrote .vmfb to path '/tmp/iree/colab_artifacts/demo_android-gpu-mali.vmfb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUaNUkS2ohRj",
        "outputId": "f68f565b-e695-418f-c351-884721b46213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#@title Download artifacts\n",
        "\n",
        "ARTIFACTS_ZIP = \"/tmp/iree_demo_colab_artifacts.zip\"\n",
        "\n",
        "print(f\"Zipping '{ARTIFACTS_DIR}' to '{ARTIFACTS_ZIP}' for download...\")\n",
        "!cd {ARTIFACTS_DIR} && zip -r {ARTIFACTS_ZIP} .\n",
        "\n",
        "# Note: you can also download files using Colab's file explorer\n",
        "try:\n",
        "  from google.colab import files\n",
        "  print(\"Downloading the artifacts zip file...\")\n",
        "  files.download(ARTIFACTS_ZIP)\n",
        "except ImportError:\n",
        "  print(\"Missing google_colab Python package, can't download files\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zipping '/tmp/iree/colab_artifacts' to '/tmp/iree_demo_colab_artifacts.zip' for download...\n",
            "  adding: demo_android-cpu-arm64-v8a.vmfb (deflated 65%)\n",
            "  adding: demo_wasm.vmfb (deflated 58%)\n",
            "  adding: demo_android-gpu-mali.vmfb (deflated 64%)\n",
            "  adding: demo_vmvx.vmfb (deflated 61%)\n",
            "Downloading the artifacts zip file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_73137f96-203e-4ed6-bc33-e8cd25e1bb75\", \"iree_demo_colab_artifacts.zip\", 14161)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}